import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
import datetime
import time

def scrape1():
    url = 'https://www.cftc.gov/dea/futures/deacmesf.htm'
    def update():
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')
        text = soup.get_text()
        return text
    text = update()
    words = ["MICRO BITCOIN", "BITCOIN", "ETHER CASH SETTLED", "MICRO ETHER"]
    #word = "BITCOIN"

    def create_multi_level_df(word: str):
        new_name = word.replace(' ', '_')
        start_index = text.find(word)

        if start_index != -1:
            blank_line_count = 0
            scraped_text = ""
            lines = text[start_index:].splitlines()
            for line in lines:
                if line.strip() == "":
                    blank_line_count += 1
                else:
                    blank_line_count = 0
                    scraped_text += line + '\n'
                if blank_line_count == 2:
                    break
            # print(scraped_text)

            # Aici extrag toate valorile din text
            values = re.findall(r'\d+\.\d+|\d+,?\d+|-?\d+', scraped_text)

            # Aici fac un multi-level df
            level_1 = ['NON-COMMERCIAL', "COMMERCIAL", "TOTAL", "NONREPORTABLE POSITIONS"]
            level_2 = [['LONG', 'SHORT', 'SPREAD'], ['LONG', 'SHORT'], ['LONG', 'SHORT'], ['LONG', 'SHORT']]
            tuples = [(j, k) for j in level_1 for k in level_2[level_1.index(j)]]
            columns = pd.MultiIndex.from_tuples(tuples)
            
            df = pd.DataFrame([values[6:15]], columns=columns, index=["Commitments"])
            new_row = pd.DataFrame([values[19:28]], columns=df.columns, index=["Changes from past week"])
            df = pd.concat([df, new_row])
            new_row1 = pd.DataFrame([values[28:37]], columns=df.columns, index=["Percent of open interest for each category of traders"])
            df = pd.concat([df, new_row1])

            missing_values = 9 - len(values[38:])
            values[38:] += [0] * missing_values
            new_row2 = pd.DataFrame([values[38:]], columns=df.columns, index=["Number of traders in each category"])
            df = pd.concat([df, new_row2])

            date = values[1:4]
            code = values[0]
            header = [f'{"/".join(date)}      Code: {code}']

            with open(f"./cft(futures_only)/{new_name}.csv", 'a') as f:
                f.write(','.join(header) + '\n')
                df.to_csv(f, index=False)
            
        else:
            print(f"{word} not found in {url}")
    for item in words:
        create_multi_level_df(item)
    print(f"It's done master!")
scrape1()



while True:
    scrape1()
    now = datetime.datetime.now()
    next_week = now + datetime.timedelta(days=7)
    # sleep until next week
    time.sleep((next_week - now).total_seconds())
